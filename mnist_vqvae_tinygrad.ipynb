{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3f5be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-3.4560264e-07, 0.99999964)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import os\n",
    "#os.environ[\"OPT\"] = '1'\n",
    "os.environ[\"GPU\"] = '1'\n",
    "import random\n",
    "from tqdm import trange\n",
    "from tinygrad.helpers import prod\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn import Conv2d\n",
    "from tinygrad.nn.optim import Adam, get_parameters\n",
    "from datasets import fetch_mnist\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = fetch_mnist()\n",
    "mu, stddev = X_train.mean(), (X_train.var() ** 0.5)\n",
    "X_train = (X_train.astype(np.float32).reshape(-1, 1, 28, 28) - mu) / stddev\n",
    "X_test = (X_test.astype(np.float32).reshape(-1, 1, 28, 28) - mu) / stddev\n",
    "X_train.mean(), X_train.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67539e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Tensor <LB (10, 4, 2, 2) op:BinaryOps.ADD> with grad None>,\n",
       " (<Tensor <LB (10, 1, 28, 28) op:BinaryOps.ADD> with grad None>,\n",
       "  <Tensor <LB (1,) op:BinaryOps.MUL> with grad None>,\n",
       "  <Tensor <LB (1,) op:BinaryOps.MUL> with grad None>),\n",
       " 97413)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upsample(x):\n",
    "  bs,c,py,px = x.shape\n",
    "  return x.reshape(bs, c, py, 1, px, 1).expand(bs, c, py, 2, px, 2).reshape(bs, c, py*2, px*2)\n",
    "\n",
    "H = 64\n",
    "EPS = 1e-8\n",
    "class AutoEncoder:\n",
    "  def __init__(self):\n",
    "    self.emb = Tensor.glorot_uniform(16, 4, requires_grad=True)  # KxD, K=8 latent space, D=4 dimensionality of embedding vector\n",
    "    # downsample\n",
    "    self.c1 = Conv2d(1, 16, kernel_size=3, stride=2)\n",
    "    self.c2 = Conv2d(16, H, kernel_size=3, stride=2)\n",
    "    self.c3 = Conv2d(H, H, kernel_size=3, padding=1)\n",
    "    self.c4 = Conv2d(H, 4, kernel_size=3, stride=2)\n",
    "    # upsample\n",
    "    self.d1 = Conv2d(4, H, kernel_size=3, padding=1)\n",
    "    self.d2 = Conv2d(H, H, kernel_size=3, padding=1)\n",
    "    self.d3 = Conv2d(H, 16, kernel_size=3, padding=(0,1,0,1))\n",
    "    self.d4 = Conv2d(16, 1, kernel_size=3)\n",
    "    \n",
    "  def encode(self, x):\n",
    "    return x.sequential([self.c1, Tensor.relu,\n",
    "                         self.c2, Tensor.relu,\n",
    "                         self.c3, Tensor.relu,\n",
    "                         self.c4])\n",
    "  \n",
    "  def decode(self, x):\n",
    "    return x.sequential([upsample, self.d1, Tensor.relu,\n",
    "                         upsample, self.d2, Tensor.relu,\n",
    "                         upsample, self.d3, Tensor.relu,\n",
    "                         upsample, self.d4])\n",
    "    \n",
    "    \n",
    "  def __call__(self, x):\n",
    "    inputs = self.encode(x)\n",
    "    flat_input = inputs.permute(0,2,3,1).reshape(-1, 4)\n",
    "    \n",
    "    # https://github.com/zalandoresearch/pytorch-vq-vae/blob/master/vq-vae.ipynb\n",
    "    distances = flat_input.square().sum(axis=1, keepdim=True) + self.emb.square().sum(axis=1) - 2 * (flat_input @ self.emb.transpose())\n",
    "    encoding_min = distances.min(axis=1, keepdim=True)\n",
    "    encodings = (-(distances-encoding_min)+EPS).relu()/EPS   # hacks for argmin\n",
    "    quantized = encodings @ self.emb\n",
    "    quantized_pl = flat_input + (quantized - flat_input).detach()   # allow the gradient to flow\n",
    "    latent = quantized_pl.reshape(inputs.shape[0], inputs.shape[2], inputs.shape[3], inputs.shape[1]).permute(0,3,1,2)    \n",
    "    \n",
    "    codebook_loss = encoding_min.mean()\n",
    "    commitment_loss = (quantized.detach() - flat_input).square().mean()   # needed to not update codebook too fast\n",
    "    \n",
    "    return self.decode(latent), codebook_loss, commitment_loss\n",
    "  \n",
    "model = AutoEncoder()\n",
    "opt = Adam(get_parameters(model), lr=1e-3)\n",
    "losses = []\n",
    "model.encode(Tensor(X_train[0:10])), model(Tensor(X_train[0:10])), sum([prod(x.shape) for x in get_parameters(model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6a581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.374684 0.063783 0.015946:  85%|████████████████████████████████████████████████████████████████████████████████████████▎               | 849/1000 [01:24<00:15,  9.59it/s]"
     ]
    }
   ],
   "source": [
    "BS = 64\n",
    "for i in (t:=trange(1000)):\n",
    "  inp = Tensor(X_train[[random.randint(0, X_train.shape[0]-1) for _ in range(BS)]])\n",
    "  ret, codebook_loss, commitment_loss = model(inp)\n",
    "  reconstruction_loss = (ret - inp).square().mean()\n",
    "  loss = reconstruction_loss + codebook_loss + 0.25*commitment_loss\n",
    "  opt.zero_grad()\n",
    "  loss.backward()\n",
    "  opt.step()\n",
    "  losses.append((reconstruction_loss.numpy()[0], codebook_loss.numpy()[0], commitment_loss.numpy()[0]))\n",
    "  t.set_description(f\"{losses[-1][0]:f} {losses[-1][1]:f} {losses[-1][2]:f}\")\n",
    "plt.ylim(0,1)\n",
    "plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8149b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = Tensor(X_test[0:5]).reshape(-1, 28)\n",
    "rec = model(Tensor(X_test[0:5]))[0]\n",
    "imshow(real.cat(rec.reshape(-1, 28), dim=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f9dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
