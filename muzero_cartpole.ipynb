{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muzero in a notebook on cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['concatenate', 'add', 'maximum', 'subtract', 'average', 'dot', 'multiply', 'f', 'minimum']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "#import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import gym\n",
    "from tqdm import trange\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.layers import *\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def toh(x,n):\n",
    "    ret = np.zeros([n])\n",
    "    ret[x] = 1.0\n",
    "    return ret\n",
    "def bstack(bb):\n",
    "    ret = [[x] for x in bb[0]]\n",
    "    for i in range(1, len(bb)):\n",
    "        for j in range(len(bb[i])):\n",
    "            ret[j].append(bb[i][j])\n",
    "    return [np.array(x) for x in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_DIM = 4\n",
    "\n",
    "# h: representation function\n",
    "# s_0 = h(o_1...o_t)\n",
    "x = o_0 = Input(env.observation_space.shape)\n",
    "x = Dense(S_DIM)(x)\n",
    "s_0 = Activation('tanh')(x)\n",
    "unh = Model(o_0, s_0, name=\"h\")\n",
    "def ht(o_0):\n",
    "    return h.predict(o_0[None])[0]\n",
    "\n",
    "# g: dynamics function (recurrent in state?) old_state+action -> state+reward\n",
    "# r_k, s_k = g(s_k-1, a_k)\n",
    "s_km1 = Input(S_DIM)\n",
    "a_k = Input(env.action_space.n)\n",
    "x = Concatenate()([s_km1, a_k])\n",
    "x = Dense(64)(x)\n",
    "x = Activation('elu')(x)\n",
    "x = Dense(64)(x)\n",
    "x = Activation('elu')(x)\n",
    "s_k = Dense(S_DIM, name='s_k')(x)\n",
    "r_k = Dense(1, name='r_k')(x)\n",
    "g = Model([s_km1, a_k], [r_k, s_k], name=\"g\")\n",
    "g.compile('adam', 'mse')\n",
    "def gt(s_km1, a_k):\n",
    "    r_k, s_k = g.predict([s_km1[None], a_k[None]])\n",
    "    return r_k[0], s_k[0]\n",
    "\n",
    "# f: prediction function -- state -> policy+value\n",
    "# p_k, v_k = f(s_k)\n",
    "x = s_k = Input(S_DIM)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('tanh')(x)\n",
    "p_k = Dense(env.action_space.n)(x)\n",
    "p_k = Activation('softmax', name='p_k')(p_k)\n",
    "v_k = Dense(1, name='v_k')(x)\n",
    "f = Model(s_k, [p_k, v_k], name=\"f\")\n",
    "f.compile('adam', 'mse')\n",
    "def ft(s_k):\n",
    "    p_k, v_k = f.predict(s_k[None])\n",
    "    return p_k[0], v_k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "o_0 (InputLayer)                [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "a_0 (InputLayer)                [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "g (Model)                       [(None, 1), (None, 4 4933        o_0[0][0]                        \n",
      "                                                                 a_0[0][0]                        \n",
      "                                                                 g[1][1]                          \n",
      "                                                                 a_1[0][0]                        \n",
      "                                                                 g[2][1]                          \n",
      "                                                                 a_2[0][0]                        \n",
      "                                                                 g[3][1]                          \n",
      "                                                                 a_3[0][0]                        \n",
      "                                                                 g[4][1]                          \n",
      "                                                                 a_4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "a_1 (InputLayer)                [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "a_2 (InputLayer)                [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "a_3 (InputLayer)                [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "a_4 (InputLayer)                [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "f (Model)                       [(None, 2), (None, 1 259         g[1][1]                          \n",
      "                                                                 g[2][1]                          \n",
      "                                                                 g[3][1]                          \n",
      "                                                                 g[4][1]                          \n",
      "                                                                 g[5][1]                          \n",
      "==================================================================================================\n",
      "Total params: 5,192\n",
      "Trainable params: 5,192\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# it's using the dynamics function for rollout search\n",
    "K = 5\n",
    "gamma = 0.95\n",
    "\n",
    "# represent\n",
    "o_0 = Input(env.observation_space.shape, name=\"o_0\")\n",
    "# don't use the h function for now\n",
    "#s_km1 = h(o_0)\n",
    "s_km1 = o_0\n",
    "\n",
    "# rollout with dynamics\n",
    "# p_k, v_k, r_k = mu(o_0, a_1_k)\n",
    "a_all, mu_all = [], []\n",
    "for k in range(K):\n",
    "    a_k = Input(env.action_space.n, name=\"a_%d\" % k)\n",
    "    r_k, s_k  = g([s_km1, a_k])\n",
    "    \n",
    "    # predict\n",
    "    p_k, v_k = f([s_k])\n",
    "    \n",
    "    # store\n",
    "    a_all.append(a_k)\n",
    "    mu_all.append([p_k, v_k, r_k])\n",
    "    s_km1 = s_k\n",
    "\n",
    "# put in the first observation and actions\n",
    "#   need policy from search\n",
    "#   need values from sum of rewards + last state value (real state?)\n",
    "#   need rewards\n",
    "#a_all = Concatenate()(a_all)\n",
    "mu = Model([o_0, a_all], mu_all)\n",
    "mu.compile('adam', 'mse')\n",
    "mu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13.801957, (1, 0, 1, 0, 1)),\n",
       " (13.794019, (0, 1, 1, 1, 0)),\n",
       " (13.793693, (0, 1, 1, 0, 1)),\n",
       " (13.792161, (1, 0, 0, 1, 1)),\n",
       " (13.766726, (1, 0, 1, 1, 0)),\n",
       " (13.763342, (1, 1, 0, 0, 1)),\n",
       " (13.755687, (0, 1, 0, 1, 1)),\n",
       " (13.705733, (0, 0, 1, 1, 1)),\n",
       " (13.683206, (1, 1, 0, 1, 0)),\n",
       " (13.522788, (1, 1, 1, 0, 0)),\n",
       " (12.379579, (0, 1, 1, 1, 1)),\n",
       " (12.347724, (1, 1, 0, 0, 0)),\n",
       " (12.130088, (1, 0, 1, 1, 1)),\n",
       " (12.074832, (1, 0, 1, 0, 0)),\n",
       " (11.83241, (1, 0, 0, 1, 0)),\n",
       " (11.82828, (0, 1, 1, 0, 0)),\n",
       " (11.777593, (1, 1, 0, 1, 1)),\n",
       " (11.623328, (1, 0, 0, 0, 1)),\n",
       " (11.567865, (0, 1, 0, 1, 0)),\n",
       " (11.367116, (0, 0, 1, 1, 0)),\n",
       " (11.343383, (0, 1, 0, 0, 1)),\n",
       " (11.328216, (1, 1, 1, 0, 1)),\n",
       " (11.130788, (0, 0, 1, 0, 1)),\n",
       " (10.976069, (0, 0, 0, 1, 1)),\n",
       " (10.821125, (1, 1, 1, 1, 0)),\n",
       " (8.384873, (1, 0, 0, 0, 0)),\n",
       " (8.063352, (0, 1, 0, 0, 0)),\n",
       " (8.006327, (1, 1, 1, 1, 1)),\n",
       " (7.8176646, (0, 0, 1, 0, 0)),\n",
       " (7.637002, (0, 0, 0, 1, 0)),\n",
       " (7.4666595, (0, 0, 0, 0, 1)),\n",
       " (5.021906, (0, 0, 0, 0, 0))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "aopts = list(itertools.product([0,1], repeat=K))\n",
    "aoptss = np.array([[toh(x, 2) for x in aa] for aa in aopts])\n",
    "aoptss = aoptss.swapaxes(0,1)\n",
    "aoptss = [aoptss[x] for x in range(5)]\n",
    "\n",
    "def search(o_0):\n",
    "    # 2^5 rollout isn't too bad, explore them all\n",
    "    # maximize value\n",
    "    o_0s = np.repeat(np.array(o_0)[None], len(aopts), axis=0)\n",
    "    ret = mu.predict([o_0s]+aoptss)\n",
    "    v = [(ret[-2][i][0], aopts[i]) for i in range(len(ret[-2]))]\n",
    "    return sorted(v, reverse=True)\n",
    "\n",
    "env.reset()\n",
    "search(env.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.75679397583008]\n",
      "[37.6257438659668]\n",
      "[36.63232421875]\n",
      "[36.23903274536133]\n",
      "[34.34711837768555]\n",
      "[33.506534576416016]\n",
      "[32.88059616088867]\n",
      "[31.765249252319336]\n",
      "[31.22316551208496]\n",
      "[30.173458099365234]\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "for _ in range(10):\n",
    "    x,y = [],[]\n",
    "    for _ in range(16):\n",
    "        o_0 = np.copy(env.state)\n",
    "        acts = search(o_0)\n",
    "        v_k, a_0k = acts[0]\n",
    "        #v_k, a_0k = acts[random.randint(0, len(acts))]\n",
    "        a_0koh = [toh(x, 2) for x in a_0k]\n",
    "        x.append([o_0]+a_0koh)\n",
    "\n",
    "        # actually act with best value policy\n",
    "        rs = []\n",
    "        for i in range(K):\n",
    "            _, r, done, _ = env.step(a_0k[i])\n",
    "            if done:\n",
    "                #r = -50\n",
    "                env.reset()\n",
    "            rs.append(r)\n",
    "\n",
    "        # compute values\n",
    "        v_0k = [v_k]\n",
    "        for r in rs[::-1]:\n",
    "            v_0k = [v_0k[0]*gamma + r] + v_0k\n",
    "\n",
    "        yl = []\n",
    "        for i in range(K):\n",
    "            yl += [a_0koh[i], v_0k[i], rs[i]]\n",
    "        y.append(yl)\n",
    "            \n",
    "    ll = mu.fit(bstack(x), bstack(y), verbose=0)\n",
    "    loss = ll.history['loss']\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 13.733291\n",
      "0 13.684348\n",
      "1 13.727105\n",
      "0 13.70251\n",
      "1 13.719481\n",
      "0 13.708284\n",
      "1 13.713237\n",
      "0 13.70372\n",
      "1 13.708823\n",
      "0 13.688849\n",
      "1 13.704804\n",
      "0 13.661925\n",
      "1 13.702993\n",
      "0 13.619447\n",
      "1 13.707948\n",
      "0 13.555988\n",
      "1 13.708226\n",
      "1 13.499552\n",
      "0 13.69616\n",
      "1 13.516931\n",
      "0 13.570954\n",
      "1 13.54375\n",
      "1 13.297528\n",
      "0 13.194484\n",
      "0 13.342956\n",
      "0 13.355192\n",
      "0 13.3951235\n",
      "0 13.186452\n",
      "0 13.456133\n",
      "1 13.270425\n",
      "0 13.476573\n",
      "1 13.379913\n",
      "0 13.480659\n",
      "1 13.4441185\n",
      "0 13.501527\n",
      "1 13.4934435\n",
      "0 13.550317\n",
      "1 13.534984\n",
      "0 13.614503\n",
      "1 13.54923\n",
      "0 13.673642\n",
      "1 13.488374\n",
      "1 13.7078085\n",
      "1 13.588584\n",
      "0 13.720469\n",
      "1 13.552429\n",
      "0 13.744243\n",
      "0 13.60601\n",
      "1 13.756001\n",
      "0 13.706918\n",
      "1 13.765517\n",
      "0 13.787965\n",
      "1 13.769981\n",
      "0 13.83617\n",
      "1 13.727666\n",
      "0 13.869744\n",
      "0 13.643475\n",
      "1 13.881594\n",
      "0 13.809009\n",
      "1 13.742021\n",
      "1 13.878515\n",
      "1 13.830179\n",
      "0 13.92369\n",
      "0 13.75325\n",
      "1 13.856716\n",
      "1 13.857788\n",
      "1 13.91124\n",
      "0 13.942697\n",
      "1 13.822467\n",
      "0 13.982777\n",
      "0 13.82396\n",
      "1 13.892095\n",
      "1 13.896438\n",
      "1 13.955777\n",
      "0 13.980973\n",
      "1 13.925969\n",
      "0 14.022838\n",
      "1 13.89408\n",
      "0 14.048903\n",
      "1 13.861461\n",
      "0 14.057389\n",
      "1 13.846858\n",
      "0 14.056499\n",
      "1 13.851026\n",
      "0 14.057905\n",
      "1 13.860605\n",
      "0 14.035913\n",
      "1 13.88774\n",
      "0 13.953425\n",
      "1 13.913949\n",
      "0 13.761669\n",
      "1 13.947053\n",
      "1 13.7105665\n",
      "0 13.648812\n",
      "0 13.770409\n",
      "0 13.692996\n",
      "0 13.820625\n",
      "1 13.549766\n",
      "0 13.843644\n",
      "1 13.687183\n"
     ]
    }
   ],
   "source": [
    "# can act?\n",
    "# not yet\n",
    "env.reset()\n",
    "for sn in range(100):\n",
    "    ret = search(env.state)\n",
    "    v,aa = ret[0]\n",
    "    print(aa[0], v)\n",
    "    env.render()\n",
    "    _,r,done,_ = env.step(aa[0])\n",
    "    if done:\n",
    "        print(\"DONE\", sn)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 491.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples\n",
      "Epoch 1/5\n",
      "100000/100000 [==============================] - 3s 30us/sample - loss: 6.4070 - p_k_loss: 0.2418 - v_k_loss: 6.1652\n",
      "Epoch 2/5\n",
      "100000/100000 [==============================] - 3s 28us/sample - loss: 2.7266 - p_k_loss: 0.2327 - v_k_loss: 2.4938\n",
      "Epoch 3/5\n",
      "100000/100000 [==============================] - 3s 28us/sample - loss: 2.3641 - p_k_loss: 0.2297 - v_k_loss: 2.1344\n",
      "Epoch 4/5\n",
      "100000/100000 [==============================] - 3s 28us/sample - loss: 2.2851 - p_k_loss: 0.2287 - v_k_loss: 2.0563\n",
      "Epoch 5/5\n",
      "100000/100000 [==============================] - 3s 27us/sample - loss: 2.2572 - p_k_loss: 0.2283 - v_k_loss: 2.0290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x153855350>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test: Can the f function learn a policy+value model\n",
    "\n",
    "x_s = []\n",
    "y_p = []\n",
    "y_v = []\n",
    "\n",
    "for _ in trange(1000):\n",
    "    env.reset()\n",
    "    rs = []\n",
    "    for _ in range(100):\n",
    "        a_k = env.action_space.sample()\n",
    "        _, r, done, _ = env.step(a_k)\n",
    "        x_s.append(env.state)\n",
    "        y_p.append(toh(a_k, 2))\n",
    "        rs.append(r)\n",
    "    v_0k = [0]\n",
    "    for r in rs[::-1]:\n",
    "        v_0k = [v_0k[0]*gamma + r] + v_0k\n",
    "    y_v += v_0k[:-1]\n",
    "x_s = np.array(x_s)\n",
    "y_p, y_v = np.array(y_p), np.array(y_v)\n",
    "    \n",
    "f.fit(x_s, [y_p, y_v], batch_size=32, epochs=5, shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 454.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples\n",
      "Epoch 1/5\n",
      "100000/100000 [==============================] - 4s 35us/sample - loss: 0.1094 - r_k_loss: 0.0491 - s_k_loss: 0.0603\n",
      "Epoch 2/5\n",
      "100000/100000 [==============================] - 3s 33us/sample - loss: 0.0285 - r_k_loss: 0.0211 - s_k_loss: 0.0073\n",
      "Epoch 3/5\n",
      "100000/100000 [==============================] - 3s 33us/sample - loss: 0.0223 - r_k_loss: 0.0166 - s_k_loss: 0.0057\n",
      "Epoch 4/5\n",
      "100000/100000 [==============================] - 3s 33us/sample - loss: 0.0201 - r_k_loss: 0.0152 - s_k_loss: 0.0049\n",
      "Epoch 5/5\n",
      "100000/100000 [==============================] - 3s 33us/sample - loss: 0.0186 - r_k_loss: 0.0144 - s_k_loss: 0.0042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15b3cbed0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test: Can the g function learn a dynamics model\n",
    "# Answer: yes!\n",
    "# Sadly, with h, this is hard to test in the whole system\n",
    "\n",
    "x_s, x_a = [], []\n",
    "y_r, y_s = [], []\n",
    "\n",
    "for _ in trange(1000):\n",
    "    env.reset()\n",
    "    for _ in range(100):\n",
    "        #env.render()\n",
    "        a_k = env.action_space.sample()\n",
    "        x_s.append(env.state)\n",
    "        x_a.append(toh(a_k, env.action_space.n))\n",
    "        _, r, done, _ = env.step(a_k)\n",
    "        y_r.append([r])\n",
    "        y_s.append(env.state)\n",
    "        #if done:\n",
    "        #    break\n",
    "    env.close()\n",
    "x_s, x_a = np.array(x_s), np.array(x_a)\n",
    "y_r, y_s = np.array(y_r), np.array(y_s)\n",
    "\n",
    "g.fit([x_s, x_a], [y_r, y_s], batch_size=32, epochs=5, shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [1.0660192] [13.723018] 1\n",
      "1 [1.0719117] [13.409712] 1\n",
      "0 [1.0903379] [13.763711] 1\n",
      "0 [1.0704638] [12.975025] 1\n",
      "0 [1.0384701] [10.96083] 0\n",
      "1 [0.9717561] [11.8278] 1\n",
      "0 [0.9688573] [9.245917] 0\n",
      "0 [0.8637582] [6.5032196] 0\n",
      "0 [0.69667184] [4.113181] 0\n",
      "1 [0.45217487] [3.8137937] 0\n",
      "0 [0.3660025] [1.9988377] 0\n",
      "1 [0.1688199] [1.580481] 0\n",
      "0 [0.11066136] [0.6227689] 0\n",
      "1 [-0.00078909] [0.32047033] 1\n",
      "1 [-0.03729492] [0.09122348] 1\n",
      "0 [-0.03628473] [-0.05037463] 1\n",
      "0 [-0.04080047] [-0.06838822] 1\n",
      "1 [-0.03352335] [-0.07491505] 1\n",
      "0 [-0.00827189] [-0.04505146] 1\n",
      "1 [-0.00728083] [-0.02573025] 1\n",
      "0 [0.02716774] [-0.01078022] 1\n",
      "1 [-0.00327633] [0.00095594] 1\n",
      "1 [-0.01499498] [0.00741518] 1\n",
      "1 [-0.03762173] [0.01040471] 1\n",
      "0 [-0.04375656] [0.01101959] 1\n",
      "1 [-0.08673285] [0.01187098] 1\n",
      "1 [-0.11904402] [0.01234138] 1\n",
      "0 [-0.13987117] [0.01221573] 1\n",
      "0 [-0.15327391] [0.01204026] 1\n",
      "0 [-0.1638348] [0.01181543] 1\n",
      "1 [-0.17894322] [0.01218116] 1\n",
      "1 [-0.19830191] [0.01247466] 1\n",
      "0 [-0.21190256] [0.0121938] 1\n",
      "1 [-0.21048354] [0.01246727] 1\n",
      "1 [-0.22104545] [0.01267993] 1\n",
      "1 [-0.22839606] [0.01283991] 1\n",
      "1 [-0.2321555] [0.01295412] 1\n",
      "1 [-0.2319934] [0.0130285] 1\n",
      "1 [-0.2281492] [0.01307046] 1\n",
      "0 [-0.2259543] [0.01265228] 1\n",
      "0 [-0.19936848] [0.01192749] 1\n",
      "0 [-0.17608586] [0.01068723] 1\n",
      "1 [-0.14475694] [0.01062405] 1\n",
      "1 [-0.13999745] [0.01046503] 1\n",
      "1 [-0.13543206] [0.01019323] 1\n",
      "1 [-0.13144842] [0.00978291] 1\n",
      "0 [-0.14624926] [0.00632679] 1\n",
      "1 [-0.1226379] [0.00502765] 1\n",
      "1 [-0.12236424] [0.00329268] 1\n",
      "1 [-0.12251747] [0.00101364] 1\n",
      "1 [-0.12324366] [-0.00193775] 1\n",
      "0 [-0.1248336] [-0.01447237] 0\n",
      "1 [-0.11883298] [-0.02173054] 0\n",
      "1 [-0.1170273] [-0.03052914] 0\n",
      "1 [-0.1141915] [-0.04064667] 0\n",
      "1 [-0.11022562] [-0.0516423] 0\n",
      "1 [-0.10508488] [-0.06290805] 0\n",
      "1 [-0.09977299] [-0.07380164] 0\n",
      "0 [-0.08734639] [-0.09283006] 0\n",
      "1 [-0.08984609] [-0.10067809] 0\n",
      "1 [-0.0889746] [-0.10651648] 0\n",
      "1 [-0.08871689] [-0.11032569] 0\n",
      "1 [-0.08903266] [-0.11226666] 0\n",
      "0 [-0.08222944] [-0.10907161] 0\n",
      "0 [-0.08911803] [-0.10146058] 0\n",
      "1 [-0.10259348] [-0.09858191] 0\n",
      "1 [-0.10476877] [-0.09464872] 0\n",
      "1 [-0.10713385] [-0.08988702] 0\n",
      "0 [-0.10986337] [-0.07781041] 0\n",
      "0 [-0.11479412] [-0.0662564] 0\n",
      "0 [-0.11388561] [-0.05547535] 0\n",
      "0 [-0.10942627] [-0.04552662] 0\n",
      "0 [-0.10320488] [-0.03641164] 0\n",
      "1 [-0.08103276] [-0.03315294] 0\n",
      "1 [-0.08432738] [-0.02949393] 0\n",
      "1 [-0.08720776] [-0.02550113] 0\n",
      "0 [-0.10745423] [-0.01654446] 0\n",
      "0 [-0.09960213] [-0.0088309] 0\n",
      "1 [-0.0671863] [-0.00621927] 0\n",
      "0 [-0.09859967] [0.00016344] 0\n",
      "0 [-0.09131922] [0.00488317] 0\n",
      "0 [-0.08423401] [0.00796616] 0\n",
      "1 [-0.04508075] [0.00839794] 0\n",
      "1 [-0.0525507] [0.00906146] 0\n",
      "1 [-0.05886801] [0.00982654] 0\n",
      "0 [-0.10080025] [0.011006] 0\n",
      "0 [-0.09446268] [0.0110091] 0\n",
      "1 [-0.05157067] [0.01050031] 0\n",
      "1 [-0.05931741] [0.01018059] 0\n",
      "0 [-0.10716175] [0.00967491] 0\n",
      "0 [-0.10394956] [0.00884807] 0\n",
      "1 [-0.06053758] [0.00820434] 0\n",
      "1 [-0.06938671] [0.00776136] 0\n",
      "1 [-0.07663883] [0.0074321] 0\n",
      "1 [-0.08259159] [0.00716031] 0\n",
      "1 [-0.08748062] [0.00691187] 0\n",
      "1 [-0.09152351] [0.00666773] 0\n",
      "0 [-0.14365046] [0.00614464] 0\n",
      "1 [-0.08803277] [0.00580513] 0\n",
      "0 [-0.1453264] [0.00531614] 0\n"
     ]
    }
   ],
   "source": [
    "# test the dynamics model\n",
    "env.reset()\n",
    "for _ in range(100):\n",
    "    env.render()\n",
    "    a_k = env.action_space.sample()\n",
    "    r_k, s_k = gt(env.state, toh(a_k, env.action_space.n))\n",
    "    p_k, v_k = ft(s_k)\n",
    "    print(a_k, r_k, v_k, np.argmax(p_k))\n",
    "    env.unwrapped.state = s_k\n",
    "    #env.step(a_k)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
