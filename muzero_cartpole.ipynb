{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muzero in a notebook on cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f', 'concatenate', 'subtract', 'multiply', 'dot', 'maximum', 'minimum', 'gamma', 'add', 'average']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import gym\n",
    "from tqdm import trange\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.layers import *\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def toh(x,n):\n",
    "    ret = np.zeros([n])\n",
    "    ret[x] = 1.0\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_DIM = 4\n",
    "\n",
    "# h: representation function\n",
    "# s_0 = h(o_1...o_t)\n",
    "x = o_0 = Input(env.observation_space.shape)\n",
    "x = Dense(S_DIM)(x)\n",
    "s_0 = Activation('tanh')(x)\n",
    "h = Model(o_0, s_0)\n",
    "def ht(o_0):\n",
    "    return h.predict(o_0[None])[0]\n",
    "\n",
    "# g: dynamics function (recurrent in state?) old_state+action -> state+reward\n",
    "# r_k, s_k = g(s_k-1, a_k)\n",
    "s_km1 = Input(S_DIM)\n",
    "a_k = Input(env.action_space.n)\n",
    "x = Concatenate()([s_km1, a_k])\n",
    "x = Dense(64)(x)\n",
    "x = Activation('elu')(x)\n",
    "x = Dense(64)(x)\n",
    "x = Activation('elu')(x)\n",
    "s_k = Dense(S_DIM, name='s_k')(x)\n",
    "r_k = Dense(1, name='r_k')(x)\n",
    "g = Model([s_km1, a_k], [r_k, s_k])\n",
    "g.compile('adam', 'mse')\n",
    "def gt(s_km1, a_k):\n",
    "    r_k, s_k = g.predict([s_km1[None], a_k[None]])\n",
    "    return r_k[0], s_k[0]\n",
    "\n",
    "# f: prediction function -- state -> policy+value\n",
    "# p_k, v_k = f(s_k)\n",
    "x = s_k = Input(S_DIM)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('tanh')(x)\n",
    "p_k = Dense(env.action_space.n)(x)\n",
    "p_k = Activation('softmax', name='p_k')(p_k)\n",
    "v_k = Dense(1, name='v_k')(x)\n",
    "f = Model(s_k, [p_k, v_k])\n",
    "def ft(s_k):\n",
    "    p_k, v_k = f.predict(s_k[None])\n",
    "    return p_k[0], v_k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's using the dynamics function for rollout search\n",
    "K = 5\n",
    "gamma = 0.997\n",
    "\n",
    "# represent\n",
    "o_0 = Input(env.observation_space.shape)\n",
    "s_km1 = h(o_0)\n",
    "\n",
    "# rollout with dynamics\n",
    "# p_k, v_k, r_k = mu(o_0, a_1_k)\n",
    "a_all, mu_all = [], []\n",
    "for k in range(K):\n",
    "    a_k = Input(env.action_space.n)\n",
    "    r_k, s_k  = g([s_km1, a_k])\n",
    "    \n",
    "    # predict\n",
    "    p_k, v_k = f([s_k])\n",
    "    \n",
    "    # store\n",
    "    a_all.append(a_k)\n",
    "    mu_all.append([p_k, v_k, r_k])\n",
    "    s_km1 = s_k\n",
    "\n",
    "# put in the first observation and actions\n",
    "#   need policy from search\n",
    "#   need values from sum of rewards + last state value (real state?)\n",
    "#   need rewards\n",
    "#a_all = Concatenate()(a_all)\n",
    "mu = Model([o_0, a_all], mu_all)\n",
    "mu.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5505225, (0, 1, 1, 0, 0)),\n",
       " (0.5449144, (0, 0, 0, 0, 0)),\n",
       " (0.5441888, (0, 1, 0, 0, 1)),\n",
       " (0.5422417, (0, 0, 1, 1, 0)),\n",
       " (0.5402329, (0, 0, 0, 1, 1)),\n",
       " (0.26654688, (0, 1, 1, 0, 1)),\n",
       " (0.1320413, (0, 1, 0, 1, 0)),\n",
       " (0.12378375, (0, 0, 0, 1, 0)),\n",
       " (0.11833585, (0, 0, 1, 1, 1)),\n",
       " (0.088117436, (0, 0, 1, 0, 0)),\n",
       " (0.083467014, (0, 0, 0, 0, 1)),\n",
       " (0.05097529, (0, 1, 1, 1, 0)),\n",
       " (-0.07591396, (0, 0, 1, 0, 1)),\n",
       " (-0.08704735, (0, 1, 0, 0, 0)),\n",
       " (-0.10349347, (0, 1, 0, 1, 1))]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "aopts = list(itertools.product([0,1], repeat=K))\n",
    "aoptss = np.array([[toh(x, 2) for x in aa] for aa in aopts])\n",
    "aoptss = aoptss.swapaxes(0,1)\n",
    "aoptss = [aoptss[x] for x in range(5)]\n",
    "\n",
    "def search(o_0):\n",
    "    # 2^5 rollout isn't too bad, explore them all\n",
    "    # maximize value\n",
    "    o_0s = np.repeat(np.array(o_0)[None], len(aopts), axis=0)\n",
    "    ret = mu.predict([o_0s]+aoptss)\n",
    "    v = [(ret[i][-2][0], aopts[i]) for i in range(len(ret))]\n",
    "    return sorted(v, reverse=True)\n",
    "    \n",
    "search(env.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 37.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[array([-0.04993264,  0.04836301, -0.04479264,  0.02209651]),\n",
       "   array([1., 0.]),\n",
       "   array([0., 1.]),\n",
       "   array([0., 1.]),\n",
       "   array([1., 0.]),\n",
       "   array([1., 0.])],\n",
       "  [array([ 0.04475481, -0.03243983,  0.00393763, -0.04384957]),\n",
       "   array([1., 0.]),\n",
       "   array([0., 1.]),\n",
       "   array([0., 1.]),\n",
       "   array([1., 0.]),\n",
       "   array([1., 0.])],\n",
       "  [array([-0.03185653,  0.04431162, -0.01077688, -0.02931607]),\n",
       "   array([1., 0.]),\n",
       "   array([0., 1.]),\n",
       "   array([0., 1.]),\n",
       "   array([1., 0.]),\n",
       "   array([1., 0.])],\n",
       "  [array([-0.01931571,  0.04927027,  0.02496572,  0.04038208]),\n",
       "   array([1., 0.]),\n",
       "   array([0., 1.]),\n",
       "   array([0., 1.]),\n",
       "   array([1., 0.]),\n",
       "   array([1., 0.])],\n",
       "  [array([-0.0198104 ,  0.02291996,  0.02285041, -0.00901822]),\n",
       "   array([1., 0.]),\n",
       "   array([0., 1.]),\n",
       "   array([0., 1.]),\n",
       "   array([1., 0.]),\n",
       "   array([1., 0.])],\n",
       "  [array([ 0.01769356, -0.02794923,  0.02159403,  0.02309088]),\n",
       "   array([1., 0.]),\n",
       "   array([0., 1.]),\n",
       "   array([0., 1.]),\n",
       "   array([1., 0.]),\n",
       "   array([1., 0.])],\n",
       "  [array([ 0.01174058, -0.04289561, -0.01523123, -0.01246234]),\n",
       "   array([1., 0.]),\n",
       "   array([0., 1.]),\n",
       "   array([0., 1.]),\n",
       "   array([1., 0.]),\n",
       "   array([1., 0.])],\n",
       "  [array([0.0439233 , 0.03590222, 0.01263925, 0.04871291]),\n",
       "   array([1., 0.]),\n",
       "   array([0., 1.]),\n",
       "   array([0., 1.]),\n",
       "   array([1., 0.]),\n",
       "   array([1., 0.])]],\n",
       " [[[array([1., 0.]),\n",
       "    array([0., 1.]),\n",
       "    array([0., 1.]),\n",
       "    array([1., 0.]),\n",
       "    array([1., 0.])],\n",
       "   0.55054915,\n",
       "   [1.0, 1.0, 1.0, 1.0, 1.0]],\n",
       "  [[array([1., 0.]),\n",
       "    array([0., 1.]),\n",
       "    array([0., 1.]),\n",
       "    array([1., 0.]),\n",
       "    array([1., 0.])],\n",
       "   0.55041033,\n",
       "   [1.0, 1.0, 1.0, 1.0, 1.0]],\n",
       "  [[array([1., 0.]),\n",
       "    array([0., 1.]),\n",
       "    array([0., 1.]),\n",
       "    array([1., 0.]),\n",
       "    array([1., 0.])],\n",
       "   0.5505217,\n",
       "   [1.0, 1.0, 1.0, 1.0, 1.0]],\n",
       "  [[array([1., 0.]),\n",
       "    array([0., 1.]),\n",
       "    array([0., 1.]),\n",
       "    array([1., 0.]),\n",
       "    array([1., 0.])],\n",
       "   0.5505642,\n",
       "   [1.0, 1.0, 1.0, 1.0, 1.0]],\n",
       "  [[array([1., 0.]),\n",
       "    array([0., 1.]),\n",
       "    array([0., 1.]),\n",
       "    array([1., 0.]),\n",
       "    array([1., 0.])],\n",
       "   0.55051994,\n",
       "   [1.0, 1.0, 1.0, 1.0, 1.0]],\n",
       "  [[array([1., 0.]),\n",
       "    array([0., 1.]),\n",
       "    array([0., 1.]),\n",
       "    array([1., 0.]),\n",
       "    array([1., 0.])],\n",
       "   0.5504743,\n",
       "   [1.0, 1.0, 1.0, 1.0, 1.0]],\n",
       "  [[array([1., 0.]),\n",
       "    array([0., 1.]),\n",
       "    array([0., 1.]),\n",
       "    array([1., 0.]),\n",
       "    array([1., 0.])],\n",
       "   0.55043274,\n",
       "   [1.0, 1.0, 1.0, 1.0, 1.0]],\n",
       "  [[array([1., 0.]),\n",
       "    array([0., 1.]),\n",
       "    array([0., 1.]),\n",
       "    array([1., 0.]),\n",
       "    array([1., 0.])],\n",
       "   0.5505185,\n",
       "   [1.0, 1.0, 1.0, 1.0, 1.0]]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = [],[]\n",
    "for _ in trange(8):\n",
    "    env.reset()\n",
    "    o_0 = np.copy(env.state)\n",
    "    acts = search(o_0)\n",
    "    v_k, a_0k = acts[0]\n",
    "    a_0koh = [toh(x, 2) for x in a_0k]\n",
    "    x.append([o_0]+a_0koh)\n",
    "    \n",
    "    # actually act with best value policy\n",
    "    rs = []\n",
    "    for i in range(K):\n",
    "        _, r, done, _ = env.step(a_0k[i])\n",
    "        rs.append(r)\n",
    "    y.append([a_0koh, v_k, rs])\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_57:0' shape=(None, 4) dtype=float32>,\n",
       " <tf.Tensor 'input_58:0' shape=(None, 2) dtype=float32>,\n",
       " <tf.Tensor 'input_59:0' shape=(None, 2) dtype=float32>,\n",
       " <tf.Tensor 'input_60:0' shape=(None, 2) dtype=float32>,\n",
       " <tf.Tensor 'input_61:0' shape=(None, 2) dtype=float32>,\n",
       " <tf.Tensor 'input_62:0' shape=(None, 2) dtype=float32>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'model_20/Identity:0' shape=(None, 2) dtype=float32>,\n",
       " <tf.Tensor 'model_20/Identity_1:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'model_19/Identity:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'model_20_1/Identity:0' shape=(None, 2) dtype=float32>,\n",
       " <tf.Tensor 'model_20_1/Identity_1:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'model_19_1/Identity:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'model_20_2/Identity:0' shape=(None, 2) dtype=float32>,\n",
       " <tf.Tensor 'model_20_2/Identity_1:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'model_19_2/Identity:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'model_20_3/Identity:0' shape=(None, 2) dtype=float32>,\n",
       " <tf.Tensor 'model_20_3/Identity_1:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'model_19_3/Identity:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'model_20_4/Identity:0' shape=(None, 2) dtype=float32>,\n",
       " <tf.Tensor 'model_20_4/Identity_1:0' shape=(None, 1) dtype=float32>,\n",
       " <tf.Tensor 'model_19_4/Identity:0' shape=(None, 1) dtype=float32>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 418.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples\n",
      "Epoch 1/5\n",
      "100000/100000 [==============================] - 3s 34us/sample - loss: 0.0156 - r_k_loss: 0.0115 - s_k_loss: 0.0040\n",
      "Epoch 2/5\n",
      "100000/100000 [==============================] - 3s 34us/sample - loss: 0.0146 - r_k_loss: 0.0111 - s_k_loss: 0.0036\n",
      "Epoch 3/5\n",
      "100000/100000 [==============================] - 3s 33us/sample - loss: 0.0143 - r_k_loss: 0.0110 - s_k_loss: 0.0033\n",
      "Epoch 4/5\n",
      "100000/100000 [==============================] - 3s 32us/sample - loss: 0.0138 - r_k_loss: 0.0107 - s_k_loss: 0.0031\n",
      "Epoch 5/5\n",
      "100000/100000 [==============================] - 3s 32us/sample - loss: 0.0136 - r_k_loss: 0.0106 - s_k_loss: 0.0030\n",
      "[[1.081461]]\n",
      "[[1.0875441]]\n",
      "[[1.0959835]]\n",
      "[[1.0935487]]\n",
      "[[1.0834298]]\n",
      "[[1.0871282]]\n",
      "[[1.0947123]]\n",
      "[[1.1018445]]\n",
      "[[1.0914918]]\n",
      "[[1.0920722]]\n",
      "[[1.093135]]\n",
      "[[1.0658582]]\n",
      "[[1.0645722]]\n",
      "[[1.0340444]]\n",
      "[[1.0189047]]\n",
      "[[1.0192426]]\n",
      "[[1.0456619]]\n",
      "[[1.0602669]]\n",
      "[[1.0588717]]\n",
      "[[0.9857284]]\n",
      "[[0.71624035]]\n",
      "[[0.37024945]]\n",
      "[[0.23297256]]\n",
      "[[0.2115975]]\n",
      "[[0.16063192]]\n",
      "[[0.15414785]]\n",
      "[[0.16608262]]\n",
      "[[0.1526202]]\n",
      "[[0.14265507]]\n",
      "[[0.11306046]]\n",
      "[[0.13852526]]\n",
      "[[0.10153192]]\n",
      "[[0.12703288]]\n",
      "[[0.11396417]]\n",
      "[[0.10068738]]\n",
      "[[0.08693345]]\n",
      "[[0.04910195]]\n",
      "[[0.06714292]]\n",
      "[[0.05546337]]\n",
      "[[0.04530741]]\n",
      "[[0.01552042]]\n",
      "[[0.02544045]]\n",
      "[[0.0035858]]\n",
      "[[0.01290774]]\n",
      "[[0.01758629]]\n",
      "[[0.0227697]]\n",
      "[[0.00043696]]\n",
      "[[0.0026284]]\n",
      "[[0.00589005]]\n",
      "[[0.00919008]]\n",
      "[[0.00908591]]\n",
      "[[0.00841555]]\n",
      "[[0.00963091]]\n",
      "[[0.01199248]]\n",
      "[[0.0109155]]\n",
      "[[0.0121806]]\n",
      "[[0.00812925]]\n",
      "[[0.00734454]]\n",
      "[[0.01705426]]\n",
      "[[0.00479974]]\n",
      "[[0.00235243]]\n",
      "[[0.01887119]]\n",
      "[[-0.00044059]]\n",
      "[[0.01939896]]\n",
      "[[-0.00208875]]\n",
      "[[0.01995292]]\n",
      "[[-0.00286493]]\n",
      "[[-0.00390589]]\n",
      "[[-0.00485891]]\n",
      "[[0.01614226]]\n",
      "[[0.01509476]]\n",
      "[[-0.0034865]]\n",
      "[[-0.003814]]\n",
      "[[0.00685424]]\n",
      "[[-0.00206023]]\n",
      "[[-0.00007007]]\n",
      "[[0.00045474]]\n",
      "[[-0.00009081]]\n",
      "[[-0.00160295]]\n",
      "[[-0.0149648]]\n",
      "[[-0.00622547]]\n",
      "[[-0.02054076]]\n",
      "[[-0.02323769]]\n",
      "[[-0.0160763]]\n",
      "[[-0.02018961]]\n",
      "[[-0.02994514]]\n",
      "[[-0.03380994]]\n",
      "[[-0.02480033]]\n",
      "[[-0.02682008]]\n",
      "[[-0.02897035]]\n",
      "[[-0.04658872]]\n",
      "[[-0.05103081]]\n",
      "[[-0.03166343]]\n",
      "[[-0.03335401]]\n",
      "[[-0.03472093]]\n",
      "[[-0.06466426]]\n",
      "[[-0.06846905]]\n",
      "[[-0.07172677]]\n",
      "[[-0.0746918]]\n",
      "[[-0.03593042]]\n"
     ]
    }
   ],
   "source": [
    "# Test: Can the g function learn a dynamics model\n",
    "# Answer: yes!\n",
    "\n",
    "x_s, x_a = [], []\n",
    "y_r, y_s = [], []\n",
    "\n",
    "for _ in trange(1000):\n",
    "    env.reset()\n",
    "    for _ in range(100):\n",
    "        #env.render()\n",
    "        a_k = env.action_space.sample()\n",
    "        x_s.append(env.state)\n",
    "        x_a.append(toh(a_k, env.action_space.n))\n",
    "        _, r, done, _ = env.step(a_k)\n",
    "        y_r.append([r])\n",
    "        y_s.append(env.state)\n",
    "        #if done:\n",
    "        #    break\n",
    "    env.close()\n",
    "x_s, x_a = np.array(x_s), np.array(x_a)\n",
    "y_r, y_s = np.array(y_r), np.array(y_s)\n",
    "\n",
    "g.fit([x_s, x_a], [y_r, y_s], batch_size=32, epochs=5, shuffle=1)\n",
    "\n",
    "env.reset()\n",
    "for _ in range(100):\n",
    "    env.render()\n",
    "    a_k = env.action_space.sample()\n",
    "    x1 = np.array(env.state)[None]\n",
    "    x2 = toh(a_k, env.action_space.n)[None]\n",
    "    r_k, s_k = g.predict([x1, x2])\n",
    "    print(r_k)\n",
    "    env.unwrapped.state = s_k[0]\n",
    "    #env.step(a_k)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
