{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla policy gradient in keras\n",
    "# https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import gym\n",
    "from tqdm import trange\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 226\n",
      "Trainable params: 226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = in1 = Input(env.observation_space.shape)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('tanh')(x)\n",
    "x = Dense(env.action_space.n)(x)\n",
    "x = Lambda(lambda x: tf.nn.log_softmax(x, axis=-1))(x)\n",
    "m = Model(in1, x)\n",
    "def loss(y_true, y_pred):\n",
    "  # y_pred is the log probs of the actions\n",
    "  # y_true is the action mask weighted by sum of rewards\n",
    "  return -tf.reduce_sum(y_true*y_pred, axis=-1)\n",
    "m.compile(Adam(1e-2), loss)\n",
    "m.summary()\n",
    "lll = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 111.86 ep_len:  80.97:  80%|████████  | 16/20 [00:20<00:04,  1.25s/it]"
     ]
    }
   ],
   "source": [
    "# this is like 5x faster than calling m.predict and picking in numpy\n",
    "pf = K.function(m.layers[0].input, tf.random.categorical(m.layers[-1].output, 1)[0])\n",
    "\n",
    "tt = trange(20)\n",
    "for epoch in tt:\n",
    "  X,Y = [], []\n",
    "  ll = []\n",
    "  while len(X) < 8192:\n",
    "    obs = env.reset()\n",
    "    acts, rews = [], []\n",
    "    while True:\n",
    "      # pick action\n",
    "      #act_dist = np.exp(m.predict_on_batch(obs[None])[0])\n",
    "      #act = np.random.choice(range(env.action_space.n), p=act_dist)\n",
    "      \n",
    "      # pick action (fast!)\n",
    "      act = pf(obs[None])[0]\n",
    "      \n",
    "      # save this state action pair\n",
    "      X.append(np.copy(obs))\n",
    "      acts.append(act)\n",
    "      \n",
    "      # take the action\n",
    "      obs, rew, done, _ = env.step(act)\n",
    "      rews.append(rew)\n",
    "      \n",
    "      if done:\n",
    "        rew_sum = np.sum(rews)\n",
    "        for act in acts:\n",
    "          act_mask = np.zeros((env.action_space.n))\n",
    "          act_mask[act] = rew_sum\n",
    "          Y.append(act_mask)\n",
    "        ll.append(rew_sum)\n",
    "        break\n",
    "        \n",
    "  loss = m.train_on_batch(np.array(X), np.array(Y))\n",
    "  lll.append((np.mean(ll), loss))\n",
    "  tt.set_description(\"loss:%7.2f ep_len:%7.2f\" % lll[-1])\n",
    "  tt.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([x[0] for x in lll])\n",
    "plot([x[1] for x in lll])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
